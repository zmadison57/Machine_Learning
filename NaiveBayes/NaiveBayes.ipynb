{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "## November 29th, 2022\n",
    "### Overview: Use Naive Bayes, Poisson Bayes, and SKLearn's Naive Bayes classifiers to predict whether an email is legitimate or spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the sms dataset\n",
    "df = pd.read_csv('sms_spam_collection.csv')\n",
    "# separate the data into the messages and labels\n",
    "X = df.Message\n",
    "y = df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages in to spam or ham.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Create a table that will allow the filter to evaluate P(H), P(S)\n",
    "        and P(w|C)\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "        '''\n",
    "        #masks for determining what messages are ham and which are spam\n",
    "        ham_mask = y == 'ham'\n",
    "        spam_mask = ~ham_mask\n",
    "        \n",
    "        #count word occurrences in ham,spam; dict records counts\n",
    "        ham_dict = dict()\n",
    "        spam_dict = dict()\n",
    "        for i, message in enumerate(X):\n",
    "            message = message.split()\n",
    "            if y.iloc[i] == 'ham':\n",
    "                for word in set(message):\n",
    "                    if word in ham_dict.keys():\n",
    "                        ham_dict[word] += message.count(word)\n",
    "                    else:\n",
    "                        ham_dict[word] = message.count(word)\n",
    "            else:\n",
    "                for word in set(message):\n",
    "                    if word in spam_dict.keys():\n",
    "                        spam_dict[word] += message.count(word)\n",
    "                    else:\n",
    "                        spam_dict[word] = message.count(word)\n",
    "        \n",
    "        #make dicts into dfs and combine into self.data (replace nans with 0 since there are 0 occurrences of that word)\n",
    "        df1 = pd.DataFrame(ham_dict,index=['ham'])\n",
    "        df2 = pd.DataFrame(spam_dict,index=['spam'])\n",
    "        self.data = df1.append(df2).fillna(0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Find P(C=k|x) for each x in X and for each class k by computing\n",
    "        P(C=k)P(x|C=k)\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Probability each message is ham, spam\n",
    "                0 column is ham\n",
    "                1 column is spam\n",
    "        '''\n",
    "        #prob of ham and spam\n",
    "        ham_prob = self.data.loc['ham'].sum()/(self.data.sum().sum())\n",
    "        spam_prob = self.data.loc['spam'].sum()/(self.data.sum().sum())\n",
    "        \n",
    "        #this is a dummy initialization of the array to be returned; the nans are taken out later\n",
    "        to_return = np.array([np.nan,np.nan])\n",
    "        \n",
    "        #we're checking each message in X (each message being a string of words)\n",
    "        for message in X:\n",
    "            #split it\n",
    "            message = message.split()\n",
    "            #keeping track of which words have already been accounted for (no want repeats)\n",
    "            tapped = set()\n",
    "            \n",
    "            #these keep track of the total probability product updated below\n",
    "            ham_product = 1\n",
    "            spam_product = 1\n",
    "            \n",
    "            #for each word\n",
    "            for word in set(message):\n",
    "                n = message.count(word)\n",
    "                    \n",
    "                #calculating prob of this word given that it's in ham; then same w/ spam\n",
    "                if word in self.data.loc['ham']:\n",
    "                    P_in_ham = self.data.loc['ham'][word]/self.data.loc['ham'].sum()\n",
    "                else:\n",
    "                    P_in_ham = 1 \n",
    "                if word in self.data.loc['spam']:\n",
    "                    P_in_spam = self.data.loc['spam'][word]/self.data.loc['spam'].sum()\n",
    "                else:\n",
    "                    P_in_spam = 1 \n",
    "                \n",
    "                #updating products\n",
    "                ham_product = ham_product * (P_in_ham**n)\n",
    "                spam_product = spam_product * (P_in_spam**n)\n",
    "            \n",
    "            #finally calc full probabilities for this message\n",
    "            prob_is_ham = ham_product*ham_prob\n",
    "            prob_is_spam = spam_product*spam_prob\n",
    "            \n",
    "            #append to return array\n",
    "            probs = np.array([prob_is_ham, prob_is_spam])\n",
    "            to_return = np.vstack([to_return,probs])\n",
    "            \n",
    "        return to_return[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Use self.predict_proba to assign labels to X,\n",
    "        the label will be a string that is either 'spam' or 'ham'\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        #get probabilities\n",
    "        probs = self.predict_proba(X)\n",
    "        \n",
    "        #get ea\n",
    "        predictions = []\n",
    "        for row in probs:\n",
    "            if row[0] >= row[1]:\n",
    "                predictions.append('ham')\n",
    "            else:\n",
    "                predictions.append('spam')\n",
    "                \n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k|x)) for each x in X and for each class k\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Probability each message is ham, spam\n",
    "                0 column is ham\n",
    "                1 column is spam\n",
    "        '''\n",
    "\n",
    "        #prob of ham and spam\n",
    "        ham_prob = self.data.loc['ham'].sum()/(self.data.sum().sum())\n",
    "        spam_prob = self.data.loc['spam'].sum()/(self.data.sum().sum())\n",
    "        \n",
    "        #this is a dummy initialization of the array to be returned; the nans are taken out later\n",
    "        to_return = np.array([np.nan,np.nan])\n",
    "        \n",
    "        #we're checking each message in X (each message being a string of words)\n",
    "        for message in X:\n",
    "            #split it\n",
    "            message = message.split()\n",
    "            #keeping track of which words have already been accounted for (no want repeats)\n",
    "            tapped = set()\n",
    "            \n",
    "            #these keep track of the total probability product updated below\n",
    "            ham_SUM = 0\n",
    "            spam_SUM = 0\n",
    "            \n",
    "            #for each word\n",
    "            for word in set(message):\n",
    "                n = message.count(word)\n",
    "                \n",
    "                #calculating prob of this word given that it's in ham; then same w/ spam \n",
    "                if word in self.data.loc['ham']:\n",
    "                    P_in_ham = (self.data.loc['ham'][word] + 1)/(self.data.loc['ham'].sum() + 2)\n",
    "                else:\n",
    "                    P_in_ham = 1\n",
    "                if word in self.data.loc['spam']:\n",
    "                    P_in_spam = (self.data.loc['spam'][word] + 1)/(self.data.loc['spam'].sum() + 2)\n",
    "                else:\n",
    "                    P_in_spam = 1\n",
    "                \n",
    "                #updating products (now log sums)\n",
    "                ham_SUM = ham_SUM + n*np.log(P_in_ham)\n",
    "                spam_SUM = spam_SUM + n*np.log(P_in_spam)\n",
    "            \n",
    "            #finally calc full probabilities for this message\n",
    "            prob_is_ham = ham_SUM + np.log(ham_prob)\n",
    "            prob_is_spam = spam_SUM + np.log(spam_prob)\n",
    "            \n",
    "            #append to return array\n",
    "            probs = np.array([prob_is_ham, prob_is_spam])\n",
    "            to_return = np.vstack([to_return,probs])\n",
    "            \n",
    "        return to_return[1:]\n",
    "\n",
    "\n",
    "    def predict_log(self, X):\n",
    "        '''\n",
    "        Use self.predict_log_proba to assign labels to X,\n",
    "        the label will be a string that is either 'spam' or 'ham'\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "        #get the log probabilities\n",
    "        probs = self.predict_log_proba(X)\n",
    "        \n",
    "        #get each prediction\n",
    "        predictions = []\n",
    "        for row in probs:\n",
    "            if row[0] >= row[1]:\n",
    "                predictions.append('ham')\n",
    "            else:\n",
    "                predictions.append('spam')\n",
    "                \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonBayesFilter(ClassifierMixin):\n",
    "    '''\n",
    "    A Naive Bayes Classifier that sorts messages in to spam or ham.\n",
    "    This classifier assumes that words are distributed like\n",
    "    Poisson random variables\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Uses bayesian inference to find the poisson rate for each word\n",
    "        found in the training set. For this we will use the formulation\n",
    "        of l = rt since we have variable message lengths.\n",
    "\n",
    "        This method creates a tool that will allow the filter to\n",
    "        evaluate P(H), P(S), and P(w|C)\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series): training data\n",
    "            y (pd.Series): training labels\n",
    "\n",
    "        Returns:\n",
    "            self: this is an optional method to train\n",
    "        '''\n",
    "\n",
    "        #masks for determining what messages are ham and which are spam\n",
    "        ham_mask = y == 'ham'\n",
    "        spam_mask = ~ham_mask\n",
    "        \n",
    "        #count word occurrences in ham and spam, store in dicts\n",
    "        ham_dict = dict()\n",
    "        spam_dict = dict()\n",
    "        \n",
    "        htot = 0\n",
    "        stot = 0\n",
    "        for i, message in enumerate(X):\n",
    "            message = message.split()\n",
    "            if y.iloc[i] == 'ham':\n",
    "                htot += len(message)\n",
    "                for word in set(message):\n",
    "                    if word in ham_dict.keys():\n",
    "                        ham_dict[word] += message.count(word)\n",
    "                    else:\n",
    "                        ham_dict[word] = message.count(word)\n",
    "            else:\n",
    "                stot += len(message)\n",
    "                for word in set(message):\n",
    "                    if word in spam_dict.keys():\n",
    "                        spam_dict[word] += message.count(word)\n",
    "                    else:\n",
    "                        spam_dict[word] = message.count(word)\n",
    "        \n",
    "        #make dicts into dfs and combine into self.data (replace nans with 0 since there are 0 occurrences of that word)\n",
    "        df1 = pd.DataFrame(ham_dict,index=['ham'])\n",
    "        df2 = pd.DataFrame(spam_dict,index=['spam'])\n",
    "        self.data = df1.append(df2).fillna(0)\n",
    "        self.htot = htot\n",
    "        self.stot = stot\n",
    "        \n",
    "        #creating and filling dicts of r values\n",
    "        self.ham_rates =  dict()\n",
    "        self.spam_rates = dict()\n",
    "        for word in self.data.loc['ham'].index:\n",
    "            self.ham_rates[word] = (self.data.loc['ham'][word]+1)/(htot+2)\n",
    "            self.spam_rates[word] = (self.data.loc['spam'][word]+1)/(stot+2)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict_log_proba(self, X):\n",
    "        '''\n",
    "        Find ln(P(C=k|x)) for each x in X and for each class\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,2): Log probability each message is ham or spam\n",
    "                column 0 is ham, column 1 is spam\n",
    "        '''\n",
    "        #prob of ham and spam\n",
    "        ham_prob = self.data.loc['ham'].sum()/(self.data.sum().sum())\n",
    "        spam_prob = self.data.loc['spam'].sum()/(self.data.sum().sum())\n",
    "        \n",
    "        #this is a dummy initialization of the array to be returned; the nans are taken out later\n",
    "        to_return = np.array([np.nan,np.nan])\n",
    "        \n",
    "        #we're checking each message in X (each message being a string of words)\n",
    "        for message in X:\n",
    "            #split it\n",
    "            message = message.split()\n",
    "            \n",
    "            #these keep track of the total probability product updated below\n",
    "            ham_SUM = 0\n",
    "            spam_SUM = 0\n",
    "            \n",
    "            #for each word\n",
    "            for word in set(message):\n",
    "                ni = message.count(word)\n",
    "                n = len(message)\n",
    "                \n",
    "                #calculating prob of this word given that it's in ham; smoooth\n",
    "                if word in self.ham_rates.keys():\n",
    "                    lam = (self.ham_rates[word]*n)\n",
    "                    P_in_ham = (ni*np.log(lam)) - lam - np.log(np.math.factorial(ni))\n",
    "                else:\n",
    "                    #lam = (2/(self.htot+2))*n\n",
    "                    P_in_ham = 0# (ni*np.log(lam)) - lam - np.log(np.math.factorial(ni))\n",
    "\n",
    "                if word in self.spam_rates.keys():\n",
    "                    lam = (self.spam_rates[word]*n)\n",
    "                    P_in_spam = (ni*np.log(lam)) - lam - np.log(np.math.factorial(ni))\n",
    "                else:\n",
    "                    #lam = (2/(self.stot+2))*n\n",
    "                    P_in_spam = 0#(ni*np.log(lam)) - lam - np.log(np.math.factorial(ni))\n",
    "                \n",
    "                #updating products\n",
    "                ham_SUM = ham_SUM + P_in_ham\n",
    "                spam_SUM = spam_SUM + P_in_spam\n",
    "            \n",
    "            #finally calc full probabilities for this message\n",
    "            prob_is_ham = ham_SUM + np.log(ham_prob)\n",
    "            prob_is_spam = spam_SUM + np.log(spam_prob)\n",
    "            \n",
    "            #append to return array\n",
    "            probs = np.array([prob_is_ham, prob_is_spam])\n",
    "            to_return = np.vstack([to_return,probs])\n",
    "            \n",
    "        return to_return[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Use self.predict_log_proba to assign labels to X\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.Series)(N,): messages to classify\n",
    "\n",
    "        Return:\n",
    "            (ndarray)(N,): label for each message\n",
    "        '''\n",
    "\n",
    "        #get the log probabilities\n",
    "        probs = self.predict_log_proba(X)\n",
    "        \n",
    "        #get each prediction\n",
    "        predictions = []\n",
    "        for row in probs:\n",
    "            if row[0] >= row[1]:\n",
    "                predictions.append('ham')\n",
    "            else:\n",
    "                predictions.append('spam')\n",
    "                \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_method(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Use sklearn's methods to transform X_train and X_test, create a\n",
    "    naïve Bayes filter, and classify the provided test set.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pandas.Series): messages to train on\n",
    "        y_train (pandas.Series): labels for X_train\n",
    "        X_test  (pandas.Series): messages to classify\n",
    "\n",
    "    Returns:\n",
    "        (ndarray): classification of X_test\n",
    "    '''\n",
    "    #create dictionary and transform training data\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_counts = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    #fit naive bayes\n",
    "    clf = MultinomialNB()\n",
    "    clf = clf.fit(train_counts, y_train)\n",
    "    \n",
    "    #classify\n",
    "    test_counts = vectorizer.transform(X_test)\n",
    "    labels = clf.predict(test_counts)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from each of the above classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes, regular prediction\n",
    "NB = NaiveBayesFilter()\n",
    "NB.fit(X[:300],y[:300])\n",
    "NB.predict(X[530:535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes, log prediction\n",
    "NB.predict_log(X[530:535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poisson Bayes prediction\n",
    "PB = PoissonBayesFilter()\n",
    "PB.fit(X[:300],y[:300])\n",
    "PB.predict(X[530:535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn prediction\n",
    "sklearn_method(X[:300],y[:300],X[530:535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530     ham\n",
       "531    spam\n",
       "532     ham\n",
       "533     ham\n",
       "534     ham\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true answers (same as all the predictions)\n",
    "y[530:535]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
